{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e2be54d-ed8e-445a-9232-8ba8e8e0b38c",
   "metadata": {},
   "source": [
    "# Final Project Team 6 ChatBot Design - https://manikandan18ramalingam-ai-models.hf.space/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c6cb2-34b8-44fa-9f10-0ef3306b385a",
   "metadata": {},
   "source": [
    "This project deals with creating a working chatbot trained on Stanford question answering data set (squad 2.0).\n",
    "The chatbot can accept the context and user questions and respond accordingly. The chat bot is sort of enterprise application which is deployed in Huggingface spaces and given public access.\n",
    "\n",
    "The chatbot can be accessed from following link.\n",
    "\n",
    "https://manikandan18ramalingam-ai-models.hf.space/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b102b54-bdd1-4cae-b31f-2556238704f2",
   "metadata": {},
   "source": [
    "## Download and Pre-process the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "228586ae-75f9-413d-a99d-c7c9b1df66d0",
   "metadata": {},
   "source": [
    "The data used is Stanford question answering data set shortly called as squad 2.0. We used squad 2.0 data set from Kaggle (https://www.kaggle.com/datasets/stanfordu/stanford-question-answering-dataset ) as the base to train our models to be used in the chatbot. Squad 2.0 data set contains large corpus of data collected on various topics from Music to Physics. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67091923-2dd8-497e-9355-e1c53238c619",
   "metadata": {},
   "source": [
    "### Install the below packages \n",
    "\n",
    "Requirement.txt would contain below libraries:-\n",
    "\n",
    "transformers\n",
    "tf-keras\n",
    "streamlit==1.38.0\n",
    "langchain-community==0.2.16\n",
    "langchain-text-splitters==0.2.4\n",
    "langchain-chroma==0.1.3\n",
    "langchain-huggingface==0.0.3\n",
    "langchain-groq==0.1.9\n",
    "unstructured==0.15.0\n",
    "unstructured[pdf]==0.15.0\n",
    "nltk==3.8.1\n",
    "jq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2006189-1070-49a4-8788-02342c7b2b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95df9a-248d-4b68-93eb-66c279febb31",
   "metadata": {},
   "source": [
    "### Install the streamlit and langchain libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdd3027-3b8f-4290-b311-970e095647ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install streamlit==1.38.0\n",
    "!pip install langchain-community==0.2.16\n",
    "!pip install langchain-text-splitters==0.2.4\n",
    "!pip install langchain-chroma==0.1.3\n",
    "!pip install langchain-huggingface==0.0.3\n",
    "!pip install langchain-groq==0.1.9\n",
    "!pip install unstructured==0.15.0\n",
    "!pip install unstructured[pdf]==0.15.0\n",
    "!pip install nltk==3.8.1\n",
    "!pip install jq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9713ca39-60b2-4659-82a3-3eaf6036c11b",
   "metadata": {},
   "source": [
    "### Import the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f25900bf-f546-496e-9457-a208fefcb982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_huggingface==0.0.3 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (0.0.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain_huggingface==0.0.3) (0.25.2)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain_huggingface==0.0.3) (0.2.41)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain_huggingface==0.0.3) (3.2.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain_huggingface==0.0.3) (0.20.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain_huggingface==0.0.3) (4.45.2)\n",
      "Requirement already satisfied: filelock in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (2023.6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (4.66.5)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.112 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (0.1.135)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (2.9.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (8.5.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (2.4.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (1.13.1)\n",
      "Requirement already satisfied: Pillow in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (10.4.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from transformers>=4.39.0->langchain_huggingface==0.0.3) (1.24.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from transformers>=4.39.0->langchain_huggingface==0.0.3) (2024.9.11)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from transformers>=4.39.0->langchain_huggingface==0.0.3) (0.4.5)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface==0.0.3) (2024.8.30)\n",
      "Requirement already satisfied: sympy in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (3.1.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (3.5.0)\n",
      "Requirement already satisfied: anyio in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (4.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (1.0.6)\n",
      "Requirement already satisfied: sniffio in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (0.14.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface==0.0.3) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /Users/diyamanipriya/myenv/lib/python3.9/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.112->langchain-core<0.3,>=0.1.52->langchain_huggingface==0.0.3) (1.2.2)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!pip install langchain_huggingface==0.0.3\n",
    "import os\n",
    "import langchain_community\n",
    "import langchain_text_splitters\n",
    "import langchain_huggingface\n",
    "import langchain_chroma\n",
    "\n",
    "from langchain_community.document_loaders import JSONLoader, DirectoryLoader\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_chroma import Chroma"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898c7630-cfef-46df-b649-ea2f7c354f83",
   "metadata": {},
   "source": [
    "### Load Huggingface embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12a53f7a-288c-47cd-b8c1-0d93d9fb0927",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/diyamanipriya/myenv/lib/python3.9/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "# loading the embedding model\n",
    "embeddings = HuggingFaceEmbeddings()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acae123-5db4-4b01-8712-70a3174e19bd",
   "metadata": {},
   "source": [
    "### Load the squad 2.0 train data set\n",
    "\n",
    "Use Json loader from langchain to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a91c4f22-ad0d-47d4-85ae-502434b0ad4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import JSONLoader, DirectoryLoader\n",
    "\n",
    "loader = JSONLoader(file_path='./train-v2.0.json', text_content=False, jq_schema='.data[].paragraphs[].context')\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85743d7c-2cdf-40e1-afc2-e1b4dd87af4f",
   "metadata": {},
   "source": [
    "### Split the text data\n",
    "\n",
    "Use CharacterTextSplitter to split the text and convert that into chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23ee9ee5-4396-471d-b096-22b064697160",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "text_splitter = CharacterTextSplitter(chunk_size=2000,\n",
    "                                      chunk_overlap=500)\n",
    "text_chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb463ea9-e72b-45ab-8e23-f740c211e743",
   "metadata": {},
   "source": [
    "### Create the Text embeddings and store it in Vector Database\n",
    "\n",
    "Use chroma DB to store the embeddings of the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b707817-8760-4612-a50b-2ee78d74bba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents Vectorized\n"
     ]
    }
   ],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    persist_directory=\"vector_db_dir\"\n",
    ")\n",
    "\n",
    "print(\"Documents Vectorized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde22b47-a0ae-4e8f-ac5a-6829d5f11266",
   "metadata": {},
   "source": [
    "### Collect the Groq API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cf266c1b-7c21-4ad0-a911-7159c4768f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "# Get the current working directory (for environments where __file__ is not defined)\n",
    "working_dir = os.getcwd()\n",
    "\n",
    "# Example usage: Combine working directory with file name\n",
    "config_data = json.load(open(f\"{working_dir}/config.json\"))\n",
    "GROQ_API_KEY = config_data[\"GROQ_API_KEY\"]\n",
    "os.environ[\"GROQ_API_KEY\"] = GROQ_API_KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b807176-9a95-40bd-b543-ec2ddcbbffd3",
   "metadata": {},
   "source": [
    "### Load the question-answering data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67e6b99f-2018-4935-a0ed-43c194e7055b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Load the question-answering pipeline\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"deepset/roberta-base-squad2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ced39b-96fe-4bcc-b823-f0a37e74a3b1",
   "metadata": {},
   "source": [
    "### Method to use pipeline response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6171b9ad-4aa1-4f6d-9f25-06ca08293f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve answer from the question-answering model\n",
    "def get_answer(question, context):\n",
    "    qa_result = qa_pipeline(question=question, context=context)\n",
    "    return qa_result.get('answer')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e42e717-d2cb-4e14-854e-641e3163af14",
   "metadata": {},
   "source": [
    "### Persist the data in vector store."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6361e68e-6971-4ed6-a294-8dad1004ce33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up vectorstore for document retrieval\n",
    "def setup_vectorstore():\n",
    "    persist_directory = os.path.join(os.path.dirname(__file__), \"vector_db_dir\")\n",
    "    vectorstore = Chroma(persist_directory=persist_directory, embedding_function=embeddings)\n",
    "    return vectorstore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9811d-e537-4898-b73f-769d09d5188e",
   "metadata": {},
   "source": [
    "### Create the Llama chat chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ec5d1b1b-9a0c-4380-9aa6-20cbac0085bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up fallback LLaMA chain\n",
    "def chat_chain(vectorstore):\n",
    "    llm = ChatGroq(model=\"llama-3.1-8b-instant\", temperature=0)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "    chain = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=retriever,\n",
    "    return_source_documents=False\n",
    ")\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643e9f3e-c66d-4b95-a3ec-de5ee8968245",
   "metadata": {},
   "source": [
    "### Create the streamlit code\n",
    "\n",
    "This is used to create context and user input text box. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c68fb4b4-7cd4-4099-bd13-f2058de59d68",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-19 21:59:25.212 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.213 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.236 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run /Users/diyamanipriya/myenv/lib/python3.9/site-packages/ipykernel_launcher.py [ARGUMENTS]\n",
      "2024-10-19 21:59:25.236 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.237 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.237 Session state does not function when running a script without `streamlit run`\n",
      "2024-10-19 21:59:25.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.238 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.239 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2024-10-19 21:59:25.239 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "\n",
    "# Streamlit UI setup\n",
    "st.set_page_config(\n",
    "    page_title=\"Question Answering ChatBot\",\n",
    "    page_icon=\"📚\",\n",
    "    layout=\"centered\"\n",
    ")\n",
    "\n",
    "# Title at the top\n",
    "st.title(\"📚 Question Answering ChatBot\")\n",
    "\n",
    "# Add a robo-themed GIF (you can replace this URL with any GIF URL you prefer)\n",
    "# Display centered GIF\n",
    "st.markdown(\n",
    "    \"\"\"\n",
    "    <div style=\"display: flex; justify-content: center;\">\n",
    "        <img src=\"https://media0.giphy.com/media/v1.Y2lkPTc5MGI3NjExZTJxcndrYW1pcnJ4bXpxNWM5eGYwa3J6d3BlNzQ4NnJsaXczYmZ4YyZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/58OujxlE7e19Mjv0gj/giphy.webp\" alt=\"GIF\" width=\"300\" height=\"300\">\n",
    "    </div>\n",
    "    \"\"\", unsafe_allow_html=True\n",
    ")\n",
    "\n",
    "# Input area for user-provided context\n",
    "context_input = st.text_area(\"Context (optional):\", placeholder=\"Provide context if available\")\n",
    "\n",
    "# \"Ask AI\" chat input field immediately after the context\n",
    "user_input = st.text_input(\"Ask AI:\")\n",
    "\n",
    "# Check for user input\n",
    "if user_input:\n",
    "    # If user provides context in the context text area, use it\n",
    "    if context_input:\n",
    "        context = context_input\n",
    "        answer = get_answer(user_input, context)\n",
    "    else:\n",
    "        # If no answer is found, fallback to LLaMA 2\n",
    "        llama_chain = chat_chain(setup_vectorstore())\n",
    "        llama_response = llama_chain.invoke({\"query\": user_input})\n",
    "        answer = llama_response[\"result\"]\n",
    "\n",
    "    # Display the answer\n",
    "    st.write(\"Answer:\", answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81917bd7-7851-4565-85d0-7bc98566cb3a",
   "metadata": {},
   "source": [
    "### Run the streamlit code to start the chat bot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58ea4bbb-31af-43f9-b917-76ba606748a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Path to your Streamlit app script\n",
    "#streamlit_app_path = \"/Users/diyamanipriya/myenv/lib/python3.9/site-packages/ipykernel_launcher.py\"\n",
    "\n",
    "# Running the Streamlit app\n",
    "#subprocess.run([\"streamlit\", \"run\", streamlit_app_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758e726f-c119-43c9-95ed-81adc845ca54",
   "metadata": {},
   "source": [
    "### Chat bot web access"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43450a18-aed5-43a5-b494-1f1187c65451",
   "metadata": {},
   "source": [
    "The streamlit app is deployed in huggingface personal space and web access is provided to chatbot via that. Since huggingface requires app.py to be created with stream lit app, multiple files are created. Also, Groq api key is personal one and cannot be shared here to load the LLM model.\n",
    "\n",
    "It can be accessed publicly using  https://manikandan18ramalingam-ai-models.hf.space/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072168a-1ba7-4c1a-9a93-066f7709fafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
